{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('summer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f35c624c100ab6f9c69edc57ae8c6f081f17166c877a33faf9b1f8132f4b016c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['the', 'entire', 'movie', 'is', 'filled', 'with', 'deja', 'vu', 'moments', '.']\n<class 'list'>\n"
    }
   ],
   "source": [
    "line = \"the entire movie is filled with deja vu moments .\"\n",
    "tokens = line.split()\n",
    "print(tokens)\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the entire movie is filled with deja vu moments .\n<class 'str'>\n"
    }
   ],
   "source": [
    "sentence = \" \".join(tokens)\n",
    "print(sentence)\n",
    "print(type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([3, 1, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "y_data = [3, 1, 2, 3, 2]\n",
    "labals = torch.LongTensor(y_data)\n",
    "print(labals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5])\ntensor([2, 0, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y = encoder.transform(y_data)\n",
    "labals = torch.LongTensor(y)\n",
    "print(labals.size())\n",
    "print(labals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "embedding = 'embed/GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(embedding, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"word ',' not in vocabulary\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bc9ae8edc313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# word2 = uniform.Uniform(-0.25, 0.25).sample(torch.Size([300]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(word2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summer/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summer/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summer/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word ',' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "word1 = model[',']\n",
    "# word2 = uniform.Uniform(-0.25, 0.25).sample(torch.Size([300]))\n",
    "print(word1)\n",
    "# print(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 256\n",
    "input_x = np.random.randn(1,value,value,3)\n",
    "input_y = np.random.randn(1,1,1,3)\n",
    "input_pow = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 256, 256, 3)\n(1, 1, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "x_shape = np.shape(input_x)\n",
    "y_shape = np.shape(input_y)\n",
    "print(x_shape)\n",
    "print(y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(65536, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(input_x,(-1,y_shape[-1]))\n",
    "x_new_shape = np.shape(x)\n",
    "print(x_new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_diff_numpy(input_x,input_y,input_z):\n",
    "    x_shape = np.shape(input_x)\n",
    "    y_shape = np.shape(input_y)\n",
    "    x = np.reshape(input_x,(-1, y_shape[-1]))\n",
    "    x_new_shape = np.shape(x)\n",
    "    y = np.reshape(input_y,(-1))\n",
    "    output = []\n",
    "    for i in range(x_new_shape[0]):\n",
    "        tmp1 = tmp2 = x[i]-y\n",
    "        for j in range(input_z-1):\n",
    "            tmp1 = tmp1*tmp2\n",
    "        output.append(tmp1)\n",
    "    output = np.reshape(output,x_shape)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[2.20741712e+00 2.75855852e+00 5.95146838e-01]\n   [8.40717772e-01 2.99419050e-03 1.08263391e-01]\n   [7.97250495e+00 6.69358725e-01 1.03383411e+00]\n   ...\n   [3.25361512e-01 3.42670060e+00 4.16250370e+00]\n   [1.64057150e+00 1.24477758e+00 1.53783977e+00]\n   [2.54592127e+00 1.46539147e-01 5.84423878e+00]]\n\n  [[9.96560299e-01 4.28190670e-02 3.96190953e-01]\n   [1.11153105e+00 9.39519453e+00 2.51459216e+00]\n   [1.69867725e+00 5.34835446e-01 1.64771723e+01]\n   ...\n   [7.18079931e+00 5.76188445e-01 1.49750257e-01]\n   [7.41225963e+00 4.37751407e-03 1.16130308e+00]\n   [3.42974986e-01 7.06249214e-01 3.65737291e-02]]\n\n  [[2.08447086e+00 3.03062919e-04 4.22950889e+00]\n   [3.40636392e+00 7.72222598e-01 8.31446614e-01]\n   [1.04916421e+00 9.83069444e-03 1.45029822e+00]\n   ...\n   [1.74915279e+00 3.82744817e-02 4.68411229e-01]\n   [3.26223997e+00 2.78888357e-01 2.51275116e+00]\n   [1.52294583e+00 2.80451700e-01 7.02686210e+00]]\n\n  ...\n\n  [[1.31700465e+00 1.04575820e-01 3.01278347e+00]\n   [6.78104960e+00 3.97215140e+00 1.64431537e-01]\n   [1.74610632e+00 3.79550526e+00 2.14338973e+00]\n   ...\n   [1.64015716e+00 1.06497962e+00 6.93857790e-03]\n   [7.72851009e+00 2.23973442e+00 3.17501002e+00]\n   [2.94742406e+00 1.09118985e-03 4.34062962e-01]]\n\n  [[3.40471761e+00 1.30790095e-01 1.24378778e+00]\n   [4.38460279e-01 1.47638199e-01 6.03057201e-02]\n   [1.47724809e+00 1.03651370e-01 1.16191515e+00]\n   ...\n   [3.13235678e+00 8.25193379e-03 8.56877031e-02]\n   [3.21807556e-01 1.45548561e+00 1.06515994e+00]\n   [1.30248944e+01 1.34375966e-01 1.38710803e+00]]\n\n  [[2.60910564e-01 2.82665181e-03 1.49350073e+00]\n   [2.04718372e+00 1.97656311e+00 7.55748005e-01]\n   [4.24171636e-01 1.96008296e-02 4.30770943e-02]\n   ...\n   [1.29888462e+00 1.40355235e+00 1.40566986e-01]\n   [2.06882800e+00 9.70296992e-01 7.70380358e+00]\n   [4.92817108e+00 1.28121731e+00 5.48556155e-04]]]]\n"
     ]
    }
   ],
   "source": [
    "output = power_diff_numpy(input_x, input_y, 2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}