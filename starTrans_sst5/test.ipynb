{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('summer': conda)",
   "display_name": "Python 3.7.6 64-bit ('summer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f35c624c100ab6f9c69edc57ae8c6f081f17166c877a33faf9b1f8132f4b016c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['the', 'entire', 'movie', 'is', 'filled', 'with', 'deja', 'vu', 'moments', '.']\n<class 'list'>\n"
    }
   ],
   "source": [
    "line = \"the entire movie is filled with deja vu moments .\"\n",
    "tokens = line.split()\n",
    "print(tokens)\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the entire movie is filled with deja vu moments .\n<class 'str'>\n"
    }
   ],
   "source": [
    "sentence = \" \".join(tokens)\n",
    "print(sentence)\n",
    "print(type(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([3, 1, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "y_data = [3, 1, 2, 3, 2]\n",
    "labals = torch.LongTensor(y_data)\n",
    "print(labals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5])\ntensor([2, 0, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y = encoder.transform(y_data)\n",
    "labals = torch.LongTensor(y)\n",
    "print(labals.size())\n",
    "print(labals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 300, 10, 1])\ntorch.Size([1, 900, 10])\ntorch.Size([1, 10, 100, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as f\n",
    " \n",
    "x = torch.arange(0, 1*300*10*1).float()\n",
    "x = x.view(1,300,10,1)\n",
    "print(x.shape)\n",
    "x1 = f.unfold(x, kernel_size=(3,1), padding=(3 // 2, 0))\n",
    "print(x1.shape)\n",
    "B, C_kh_kw, L = x1.size()\n",
    "x1 = x1.permute(0, 2, 1)\n",
    "x1 = x1.view(B, L, -1, 3, 3)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 6, 50, 1, 3])\ntorch.Size([1, 6, 50, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "q = torch.arange(0,1*6*50*1*10)\n",
    "q = q.view(1,6,50,1,10)\n",
    "k = torch.arange(0,1*6*50*3*10)\n",
    "k = k.view(1,6,50,3,10)\n",
    "out = torch.matmul(q, k.transpose(-1,-2))\n",
    "out2 = q * k\n",
    "print(out.shape)\n",
    "print(out2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(1,2)\n",
    "b = torch.Tensor(3,2,1)\n",
    "c = torch.matmul(a,b)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 2, 2])\ntensor([[[ 7., 10.],\n         [15., 22.]],\n\n        [[ 9.,  6.],\n         [19., 14.]],\n\n        [[ 3.,  4.],\n         [ 7., 10.]]])\ntensor([[19., 20.],\n        [41., 46.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[[1,2],[3,4]],[[1,2],[3,4]],[[1,2],[3,4]]])\n",
    "b = torch.Tensor([[[1,2],[3,4]],[[1,2],[4,2]],[[1,2],[1,1]]])\n",
    "c = torch.matmul(a,b)\n",
    "print(c.shape)\n",
    "print(c)\n",
    "print(c.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.0900, 0.2447, 0.6652],\n        [0.0900, 0.2447, 0.6652]])\n"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Softmax(dim=-1)\n",
    "input = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(10, 1).byte()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10, dtype=torch.long).view(1,10).unsqueeze(2)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 5])\ntensor([[False, False, False,  True,  True]])\ntensor([[False, False, False, False,  True,  True]])\ntensor([[False]])\ntorch.Size([1, 1, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.Tensor([[1,1,1,0,0]])\n",
    "print(mask.shape)\n",
    "mask = (mask.eq(False))\n",
    "print(mask)\n",
    "smask = torch.cat([torch.zeros(1, 1).byte().to(mask), mask], 1)\n",
    "print(smask)\n",
    "\n",
    "test = torch.zeros(1, 1).byte().to(mask)\n",
    "print(test)\n",
    "\n",
    "ex_mask = mask[:, None, :, None]\n",
    "print(ex_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_len_to_mask(seq_len, max_len=None):\n",
    "    r\"\"\"\n",
    "    将一个表示sequence length的一维数组转换为二维的mask，不包含的位置为0。\n",
    "    转变 1-d seq_len到2-d mask.\n",
    "    .. code-block::\n",
    "    \n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.size())\n",
    "        torch.Size([14, 15])\n",
    "        >>> seq_len = np.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.shape)\n",
    "        (14, 15)\n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len, max_len=100)\n",
    "        >>>print(mask.size())\n",
    "        torch.Size([14, 100])\n",
    "    :param np.ndarray,torch.LongTensor seq_len: shape将是(B,)\n",
    "    :param int max_len: 将长度pad到这个长度。默认(None)使用的是seq_len中最长的长度。但在nn.DataParallel的场景下可能不同卡的seq_len会有\n",
    "        区别，所以需要传入一个max_len使得mask的长度是pad到该长度。\n",
    "    :return: np.ndarray, torch.Tensor 。shape将是(B, max_length)， 元素类似为bool或torch.uint8\n",
    "    \"\"\"\n",
    "    if isinstance(seq_len, np.ndarray):\n",
    "        assert len(np.shape(seq_len)) == 1, f\"seq_len can only have one dimension, got {len(np.shape(seq_len))}.\"\n",
    "        max_len = int(max_len) if max_len else int(seq_len.max())\n",
    "        broad_cast_seq_len = np.tile(np.arange(max_len), (len(seq_len), 1))\n",
    "        mask = broad_cast_seq_len < seq_len.reshape(-1, 1)\n",
    "\n",
    "    elif isinstance(seq_len, torch.Tensor):\n",
    "        assert seq_len.dim() == 1, f\"seq_len can only have one dimension, got {seq_len.dim() == 1}.\"\n",
    "        batch_size = seq_len.size(0)\n",
    "        max_len = int(max_len) if max_len else seq_len.max().long()\n",
    "        broad_cast_seq_len = torch.arange(max_len).expand(batch_size, -1).to(seq_len)\n",
    "        mask = broad_cast_seq_len.lt(seq_len.unsqueeze(1))\n",
    "    else:\n",
    "        raise TypeError(\"Only support 1-d numpy.ndarray or 1-d torch.Tensor.\")\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n        10., 10., 10., 10.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "seq_len = torch.full((32,), 10)\n",
    "print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def seq_len_to_mask(seq_len, max_len=None):\n",
    "    r\"\"\"\n",
    "    将一个表示sequence length的一维数组转换为二维的mask，不包含的位置为0。\n",
    "    转变 1-d seq_len到2-d mask.\n",
    "    .. code-block::\n",
    "    \n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.size())\n",
    "        torch.Size([14, 15])\n",
    "        >>> seq_len = np.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len)\n",
    "        >>> print(mask.shape)\n",
    "        (14, 15)\n",
    "        >>> seq_len = torch.arange(2, 16)\n",
    "        >>> mask = seq_len_to_mask(seq_len, max_len=100)\n",
    "        >>>print(mask.size())\n",
    "        torch.Size([14, 100])\n",
    "    :param np.ndarray,torch.LongTensor seq_len: shape将是(B,)\n",
    "    :param int max_len: 将长度pad到这个长度。默认(None)使用的是seq_len中最长的长度。但在nn.DataParallel的场景下可能不同卡的seq_len会有\n",
    "        区别，所以需要传入一个max_len使得mask的长度是pad到该长度。\n",
    "    :return: np.ndarray, torch.Tensor 。shape将是(B, max_length)， 元素类似为bool或torch.uint8\n",
    "    \"\"\"\n",
    "    if isinstance(seq_len, np.ndarray):\n",
    "        assert len(np.shape(seq_len)) == 1, f\"seq_len can only have one dimension, got {len(np.shape(seq_len))}.\"\n",
    "        max_len = int(max_len) if max_len else int(seq_len.max())\n",
    "        broad_cast_seq_len = np.tile(np.arange(max_len), (len(seq_len), 1))\n",
    "        mask = broad_cast_seq_len < seq_len.reshape(-1, 1)\n",
    "\n",
    "    elif isinstance(seq_len, torch.Tensor):\n",
    "        assert seq_len.dim() == 1, f\"seq_len can only have one dimension, got {seq_len.dim() == 1}.\"\n",
    "        batch_size = seq_len.size(0)\n",
    "        max_len = int(max_len) if max_len else seq_len.max().long()\n",
    "        broad_cast_seq_len = torch.arange(max_len).expand(batch_size, -1).to(seq_len)\n",
    "        mask = broad_cast_seq_len.lt(seq_len.unsqueeze(1))\n",
    "    else:\n",
    "        raise TypeError(\"Only support 1-d numpy.ndarray or 1-d torch.Tensor.\")\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n        10., 10., 10., 10.])\ntorch\ntensor([[True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "seq_len = torch.full((32,), 10)\n",
    "print(seq_len)\n",
    "mask = seq_len_to_mask(seq_len)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "print(a)\n",
    "a = a.expand(32,-1)\n",
    "print(a)\n",
    "a = a.lt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLen_in_batch(sequences, device):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        cnt = 0\n",
    "        for num in sequence:\n",
    "            if num != 0:\n",
    "                cnt += 1\n",
    "        result.append(cnt)\n",
    "    return torch.Tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "x = torch.Tensor([[1,2,0,0,0],[1,2,4,5,8]])\n",
    "y = getLen_in_batch(x, device)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = torch.Tensor(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}